{
    "solution_name": "PINNs (Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations)",
    "simplified_problem": "Solving PDEs with neural networks while incorporating physical laws.",
    "problem_it_solved": "Traditional numerical methods for solving partial differential equations (PDEs) require discretization of the domain into meshes, which becomes computationally prohibitive for high-dimensional problems and complex geometries. Additionally, these methods struggle with inverse problems where parameters or initial/boundary conditions are unknown, and they cannot easily incorporate noisy or sparse observational data.",
    "historical_context": "Before 2017, solving PDEs relied primarily on classical numerical methods like finite difference, finite element, and spectral methods. These approaches required careful mesh generation and became computationally expensive for high-dimensional problems (curse of dimensionality). For inverse problems, traditional methods often needed specialized algorithms and struggled with ill-posed problems. Machine learning approaches existed but typically required large datasets and didn't naturally incorporate physical laws. There was a growing need for methods that could solve both forward and inverse problems in a unified framework while respecting the underlying physics.",
    "landmark_solution_details": {
        "domain": "Scientific Machine Learning",
        "title": "Physics-Informed Neural Networks (PINNs)",
        "concept": "A neural network is trained to approximate the solution of a PDE by minimizing a loss function that combines the PDE residual (how well the network satisfies the PDE), boundary/initial conditions, and observational data. The key insight is that automatic differentiation can compute exact derivatives of the network output with respect to inputs, allowing the PDE to be enforced as a soft constraint during training.",
        "math_foundation": "For a PDE of the form u_t + N[u] = 0 where N is a differential operator, the PINN loss is: L = L_data + L_PDE + L_BC/IC. The PDE residual is computed as: f(t,x) = u_t(t,x) + N[u(t,x)], where derivatives are computed via automatic differentiation. The loss becomes: L = (1/N_data)\u03a3|u(t_i,x_i) - u_i|^2 + (1/N_PDE)\u03a3|f(t_j,x_j)|^2 + (1/N_BC)\u03a3|u(t_k,x_k) - g(t_k,x_k)|^2.",
        "implementation": "A fully-connected neural network takes spatiotemporal coordinates (t,x) as inputs and outputs the solution u(t,x). The network is trained by minimizing the composite loss using gradient-based optimizers. Automatic differentiation computes all required derivatives exactly. For inverse problems, unknown parameters are treated as additional trainable variables. No mesh generation is required - training points can be sampled randomly from the domain.",
        "verification": "PINNs successfully solved classical PDEs like Burgers' equation, Schr\u00f6dinger equation, and Navier-Stokes equations with accuracy comparable to traditional methods. For inverse problems, PINNs recovered unknown parameters (e.g., diffusion coefficients) from sparse observations. The method demonstrated effectiveness in high-dimensional problems where traditional methods fail.",
        "inspiration": "Classical physics (conservation laws and governing equations) combined with modern deep learning (automatic differentiation and universal approximation)."
    }
}