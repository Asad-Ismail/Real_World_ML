{
    "solution_name": "MAML (Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks)",
    "simplified_problem": "Fast adaptation to new tasks with minimal data",
    "problem_it_solved": "Deep learning models require large amounts of task-specific data and extensive training to achieve good performance on new tasks. When faced with a new task with only a few examples (few-shot learning), standard fine-tuning approaches fail because the model either overfits to the small dataset or requires careful hyperparameter tuning and regularization to prevent catastrophic forgetting of previously learned knowledge.",
    "historical_context": "Before MAML, few-shot learning was primarily approached through metric learning methods (like Siamese networks or prototypical networks) that learned fixed embeddings and compared new examples to known prototypes. These methods were limited to specific domains and couldn't easily incorporate prior knowledge from related tasks. Alternatively, transfer learning involved pre-training on a large dataset and fine-tuning on the new task, but this required substantial task-specific data and careful tuning to avoid overfitting. There was no principled way to learn \"how to learn\" new tasks quickly with minimal data.",
    "landmark_solution_details": {
        "domain": "Meta-Learning / Few-Shot Learning",
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "concept": "MAML learns good parameter initializations that can be quickly adapted to new tasks with just a few gradient steps. Instead of learning a fixed model, it learns a set of meta-parameters \u03b8 such that when faced with a new task, a small number of gradient updates on a small support set produces effective task-specific parameters. The key insight is to optimize for few-shot generalization performance across tasks during meta-training.",
        "math_foundation": "Meta-training objective: min_\u03b8 \u03a3_T L_T(\u03b8 - \u03b1\u2207_\u03b8 L_T(\u03b8)) where L_T is the loss on task T, and the inner gradient step \u03b8' = \u03b8 - \u03b1\u2207_\u03b8 L_T(\u03b8) represents the adaptation to task T. The outer optimization finds \u03b8 that minimizes the post-adaptation loss across all tasks. Second-order gradients are computed through the inner optimization step using the chain rule.",
        "implementation": "1. Sample a batch of tasks T_i from the task distribution. 2. For each task, split data into support set D_i^s and query set D_i^q. 3. Compute adapted parameters \u03b8_i' = \u03b8 - \u03b1\u2207_\u03b8 L_T(D_i^s, \u03b8). 4. Update meta-parameters \u03b8 \u2190 \u03b8 - \u03b2\u2207_\u03b8 \u03a3_i L_T(D_i^q, \u03b8_i'). This requires computing second-order derivatives (Hessian) but can be approximated with first-order methods (FOMAML) for efficiency.",
        "verification": "MAML achieved state-of-the-art results on few-shot classification benchmarks like Omniglot (5-way, 1-shot: 98.7% accuracy) and Mini-ImageNet (5-way, 1-shot: 48.70% accuracy), significantly outperforming prior methods. It also demonstrated success in few-shot regression and reinforcement learning tasks, proving its model-agnostic nature.",
        "inspiration": "Optimization theory (gradient-based optimization), transfer learning (learning transferable representations), and classical meta-learning approaches (learning to learn)."
    }
}