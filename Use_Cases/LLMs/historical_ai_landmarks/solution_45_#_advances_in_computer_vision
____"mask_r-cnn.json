{
    "solution_name": "\n    # Advances in Computer Vision\n    \"Mask R-CNN (Mask R-CNN)\",\n    \"Inception-v3 (Rethinking the Inception Architecture for Computer Vision)\",\n    \"DenseNet (Densely Connected Convolutional Networks)\",\n    \"Vision Transformer (An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale)\",\n    \"SSD (SSD: Single Shot MultiBox Detector)\",\n    \"FPN (Feature Pyramid Networks for Object Detection)\",\n    \"SqueezeNet (SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size)\",\n\n    # Advances in Natural Language Processing (The LLM Era)\n    \"GPT-2 (Language Models are Unsupervised Multitask Learners)\",\n    \"GPT-3 (Language Models are Few-Shot Learners)\",\n    \"T5 (Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer)\",\n    \"RoBERTa (RoBERTa: A Robustly Optimized BERT Pretraining Approach)\",\n    \"Scaling Laws for Neural Language Models (Scaling Laws for Neural Language Models)\",\n    \"Longformer (Longformer: The Long-Document Transformer)\",\n\n    # Generative Models: Evolution and New Frontiers\n    \"StyleGAN (A Style-Based Generator Architecture for Generative Adversarial Networks)\",\n    \"Latent Diffusion Models (High-Resolution Image Synthesis with Latent Diffusion Models)\",\n    \"WaveNet (WaveNet: A Generative Model for Raw Audio)\",\n    \"VQ-VAE (Neural Discrete Representation Learning)\",\n    \"Glow (Glow: Generative Flow with Invertible 1x1 Convolutions)\",\n\n    # Reinforcement Learning: Deepening the Foundations\n    \"A3C (Asynchronous Methods for Deep Reinforcement Learning)\",\n    \"SAC (Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor)\",\n    \"MuZero (Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model)\",\n\n    # Self-Supervised and Unsupervised Learning\n    \"SimCLR (A Simple Framework for Contrastive Learning of Visual Representations)\",\n    \"MoCo (Momentum Contrast for Unsupervised Visual Representation Learning)\",\n    BYOL (Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning)",
    "simplified_problem": "Instance-level object segmentation",
    "problem_it_solved": "While Faster R-CNN could accurately detect and classify objects with bounding boxes, it could not produce pixel-accurate masks that delineate the exact shape of each detected object. This limitation prevented applications requiring precise object boundaries, such as medical imaging, robotics, and image editing.",
    "historical_context": "By 2016, Faster R-CNN had become the dominant framework for object detection, using a Region Proposal Network (RPN) to propose object regions and a second-stage network to classify and refine bounding boxes. However, the second stage only output coarse bounding boxes and class labels. Earlier work like DeepMask and FCIS attempted pixel-level segmentation but were either slow or suffered from systematic overlaps between adjacent instances. There was no unified, end-to-end system that could simultaneously detect objects and generate high-quality segmentation masks.",
    "landmark_solution_details": {}
}