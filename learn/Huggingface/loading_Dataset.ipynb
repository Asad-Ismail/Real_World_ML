{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "# Third-party imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_categories(dataset):\n",
    "    \"\"\"\n",
    "    Analyze clothing categories in a fashion dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Statistics for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get category names from features\n",
    "    category_names = dataset['train'].features['objects'].feature['category'].names\n",
    "    \n",
    "    # Initialize statistics\n",
    "    stats = defaultdict(lambda: {\n",
    "        'count': 0,\n",
    "        'total_area': 0,\n",
    "        'areas': []\n",
    "    })\n",
    "    \n",
    "    # Process training set\n",
    "    print(\"Analyzing object statistics...\")\n",
    "    for item in tqdm(dataset['train']):\n",
    "        objects = item['objects']\n",
    "        for cat_id, area in zip(objects['category'], objects['area']):\n",
    "            cat_name = category_names[cat_id]\n",
    "            stats[cat_name]['count'] += 1\n",
    "            stats[cat_name]['total_area'] += area\n",
    "            stats[cat_name]['areas'].append(area)\n",
    "    \n",
    "    # Calculate statistics and create DataFrame\n",
    "    data = []\n",
    "    for cat, metrics in stats.items():\n",
    "        if metrics['count'] > 0:  # Avoid division by zero\n",
    "            data.append({\n",
    "                'category': cat,\n",
    "                'count': metrics['count'],\n",
    "                'avg_area': metrics['total_area'] / metrics['count'],\n",
    "                'area_std': np.std(metrics['areas']),\n",
    "                'is_part': cat.lower() in {'collar', 'pocket', 'sleeve', \n",
    "                                         'zipper', 'button', 'buckle'}\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate combined score and sort\n",
    "    df['score'] = df['count'] * df['avg_area']\n",
    "    df = df.sort_values('score', ascending=False)\n",
    "    \n",
    "    # Filter and display main garments\n",
    "    main_garments = df[~df['is_part']].head(10)\n",
    "    print(\"\\nTop 10 Main Garments by frequency and size:\")\n",
    "    print(main_garments[['category', 'count', 'avg_area']].round(2).to_string())\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(main_garments['category'], main_garments['avg_area'])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Average Area by Category')\n",
    "    plt.ylabel('Average Area (pixelsÂ²)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"detection-datasets/fashionpedia\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "print(\"Dataset loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_categories(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_category_images(\n",
    "    dataset_dict,\n",
    "    categories: List[str],\n",
    "    n_train: int = 100,\n",
    "    n_val: int = 20,\n",
    "    seed: int = 42\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    Select images containing ALL specified categories for training and validation.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dict: HuggingFace DatasetDict\n",
    "        categories: List of category names to include\n",
    "        n_train: Number of training images to select\n",
    "        n_val: Number of validation images to select\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (training_dataset, validation_dataset)\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Access the training split\n",
    "    dataset = dataset_dict['train']\n",
    "    \n",
    "    # Get category IDs from names\n",
    "    category_ids = {\n",
    "        name: idx for idx, name in enumerate(\n",
    "            dataset.features['objects'].feature['category'].names\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Convert input categories to IDs\n",
    "    target_cat_ids = {category_ids[cat] for cat in categories if cat in category_ids}\n",
    "    \n",
    "    # Find images containing ALL target categories\n",
    "    valid_indices = []\n",
    "    for idx, item in enumerate(dataset):\n",
    "        cats_in_image = set(item['objects']['category'])\n",
    "        # Check if ALL target categories are in this image\n",
    "        if target_cat_ids.issubset(cats_in_image):\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    # Ensure we have enough images\n",
    "    total_needed = n_train + n_val\n",
    "    if len(valid_indices) < total_needed:\n",
    "        raise ValueError(\n",
    "            f\"Not enough images with ALL specified categories. \"\n",
    "            f\"Found {len(valid_indices)}, need {total_needed}. \"\n",
    "            f\"Try reducing n_train and n_val or selecting fewer categories.\"\n",
    "        )\n",
    "    \n",
    "    # Shuffle indices\n",
    "    random.shuffle(valid_indices)\n",
    "    \n",
    "    # Split into train and val\n",
    "    train_indices = valid_indices[:n_train]\n",
    "    val_indices = valid_indices[n_train:n_train + n_val]\n",
    "    \n",
    "    # Create new datasets\n",
    "    train_dataset = dataset.select(train_indices)\n",
    "    val_dataset = dataset.select(val_indices)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nDataset split statistics:\")\n",
    "    print(f\"Total images with all categories: {len(valid_indices)}\")\n",
    "    print(f\"Training images: {len(train_dataset)}\")\n",
    "    print(f\"Validation images: {len(val_dataset)}\")\n",
    "    \n",
    "    # Print category distribution\n",
    "    print(\"\\nCategory distribution:\")\n",
    "    for split_name, split_data in [(\"Train\", train_dataset), (\"Val\", val_dataset)]:\n",
    "        print(f\"\\n{split_name} split:\")\n",
    "        cat_counts = defaultdict(int)\n",
    "        for item in split_data:\n",
    "            for cat_id in item['objects']['category']:\n",
    "                if cat_id in target_cat_ids:\n",
    "                    cat_name = dataset.features['objects'].feature['category'].names[cat_id]\n",
    "                    cat_counts[cat_name] += 1\n",
    "        \n",
    "        for cat in categories:\n",
    "            print(f\"{cat}: {cat_counts[cat]} instances\")\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"detection-datasets/fashionpedia\")\n",
    "print(\"Dataset loaded\")\n",
    "\n",
    "# Try with fewer categories first to find images with all categories\n",
    "categories_of_interest = [\n",
    "    \"pants\",\n",
    "     \"bag, wallet\", \n",
    "    \"shirt, blouse\"  # Starting with just two categories as example\n",
    "]\n",
    "\n",
    "try:\n",
    "    train_ds, val_ds = select_category_images(\n",
    "        dataset,\n",
    "        categories=categories_of_interest,\n",
    "        n_train=200,  # Reduced numbers since we need images with ALL categories\n",
    "        n_val=50\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Try reducing the number of categories or the required images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_dataset(\n",
    "    dataset,\n",
    "    categories: List[str],\n",
    "    save_dir: str,\n",
    "    num_images: int = 5,\n",
    "    thickness: int = 2,\n",
    "    font_scale: float = 0.8\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualize images with bounding boxes and labels using OpenCV.\n",
    "    \n",
    "    Args:\n",
    "        dataset: HuggingFace dataset split\n",
    "        categories: List of category names to highlight\n",
    "        save_dir: Directory to save visualizations\n",
    "        num_images: Number of images to visualize\n",
    "        thickness: Line thickness for bounding boxes\n",
    "        font_scale: Font scale for labels\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Get category IDs\n",
    "    category_ids = {\n",
    "        name: idx for idx, name in enumerate(\n",
    "            dataset.features['objects'].feature['category'].names\n",
    "        )\n",
    "    }\n",
    "    target_cat_ids = {category_ids[cat] for cat in categories}\n",
    "    \n",
    "    # Create color map for categories (BGR format for OpenCV)\n",
    "    np.random.seed(42)  # for reproducible colors\n",
    "    colors = np.random.randint(0, 255, size=(len(categories), 3)).tolist()\n",
    "    color_map = dict(zip(categories, colors))\n",
    "    \n",
    "    # Font for OpenCV\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    # Process specified number of images\n",
    "    for i in range(min(num_images, len(dataset))):\n",
    "        try:\n",
    "            example = dataset[i]\n",
    "            \n",
    "            # Convert PIL image to numpy array if necessary\n",
    "            image = np.array(example['image'])\n",
    "            \n",
    "            # Convert to BGR format for OpenCV\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            objects = example['objects']\n",
    "            \n",
    "            # Get image dimensions\n",
    "            img_height, img_width = image.shape[:2]\n",
    "            print(f\"Processing image {i+1}, shape: {image.shape}\")\n",
    "            \n",
    "            # Create a copy of the image to draw on\n",
    "            img_draw = image.copy()\n",
    "            \n",
    "            # Draw bounding boxes and labels\n",
    "            for bbox, cat_id in zip(objects['bbox'], objects['category']):\n",
    "                if cat_id in target_cat_ids:\n",
    "                    cat_name = dataset.features['objects'].feature['category'].names[cat_id]\n",
    "                    \n",
    "                    # Get bbox coordinates\n",
    "                    x1, y1, x2, y2 = map(int, bbox)  # Convert to integers for OpenCV\n",
    "                    \n",
    "                    # Verify if bbox is within reasonable bounds\n",
    "                    if (x1 < 0 or y1 < 0 or \n",
    "                        x2 > img_width or \n",
    "                        y2 > img_height or \n",
    "                        x2-x1 <= 0 or y2-y1 <= 0):\n",
    "                        print(f\"Warning: Invalid bbox for {cat_name} in image {i+1}\")\n",
    "                        print(f'Box is {xy},{y1}, {x2}, {y2} for image w {img_width}, {img_height}')\n",
    "                        continue\n",
    "                    \n",
    "                    # Get color for this category\n",
    "                    color = color_map[cat_name]\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    cv2.rectangle(img_draw, (x1, y1), (x2, y2), color, thickness)\n",
    "                    \n",
    "                    # Add label with background\n",
    "                    label = cat_name\n",
    "                    (label_w, label_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                    \n",
    "                    # Draw label background\n",
    "                    label_y = max(y1 - label_h - 10, 0)  # Keep label above box but within image\n",
    "                    cv2.rectangle(\n",
    "                        img_draw,\n",
    "                        (x, label_y),\n",
    "                        (x + label_w, label_y + label_h + 10),\n",
    "                        color,\n",
    "                        -1  # Filled rectangle\n",
    "                    )\n",
    "                    \n",
    "                    # Draw label text (white)\n",
    "                    cv2.putText(\n",
    "                        img_draw,\n",
    "                        label,\n",
    "                        (x1, label_y + label_h + 5),\n",
    "                        font,\n",
    "                        font_scale,\n",
    "                        (255, 255, 255),  # White text\n",
    "                        thickness\n",
    "                    )\n",
    "            \n",
    "            # Add title (black text with white background)\n",
    "            title = f'Image {i+1}'\n",
    "            (title_w, title_h), _ = cv2.getTextSize(title, font, 1, thickness)\n",
    "            \n",
    "            # Draw title background\n",
    "            cv2.rectangle(\n",
    "                img_draw,\n",
    "                (10, 10),\n",
    "                (10 + title_w, 10 + title_h + 10),\n",
    "                (255, 255, 255),\n",
    "                -1\n",
    "            )\n",
    "            \n",
    "            # Draw title text\n",
    "            cv2.putText(\n",
    "                img_draw,\n",
    "                title,\n",
    "                (10, 10 + title_h + 5),\n",
    "                font,\n",
    "                1,\n",
    "                (0, 0, 0),  # Black text\n",
    "                thickness\n",
    "            )\n",
    "            \n",
    "            # Save image\n",
    "            save_path = os.path.join(save_dir, f'image_{i+1:04d}.jpg')\n",
    "            cv2.imwrite(save_path, img_draw)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Processed {i+1} images\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {i+1}: {str(e)}\")\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "    \n",
    "    print(f\"Completed! Saved {min(num_images, len(dataset))} visualizations to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and save validation images\n",
    "print(\"\\nSaving validation set visualizations...\")\n",
    "visualize_and_save_dataset(\n",
    "    val_ds,\n",
    "    categories_of_interest,\n",
    "    num_images=50,\n",
    "    save_dir='val_visualizations'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
