# FlashAttention 2 (compatible with torch 2.3, requires recompile or prebuilt wheels if available)
flash-attn==2.5.4

# Hugging Face ecosystem
torch==2.1.0
transformers==4.36.2
datasets==2.16.1
accelerate==0.25.0
peft==0.7.1
trl==0.7.11
tqdm